{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "af938e0e",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'model_pipeline'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 17\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01margparse\u001b[39;00m\n\u001b[1;32m     16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mmodel_pipeline\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;241m*\u001b[39m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mprepare_step\u001b[39m():\n\u001b[1;32m     20\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Execute data preparation step.\"\"\"\u001b[39;00m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'model_pipeline'"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "\"\"\"\n",
    "Main CLI execution file for ML Pipeline\n",
    "Execute different pipeline steps via command-line arguments.\n",
    "\n",
    "Usage:\n",
    "    python main.py --prepare              # Prepare data only\n",
    "    python main.py --train                # Train model\n",
    "    python main.py --evaluate             # Evaluate model\n",
    "    python main.py --save                 # Save model\n",
    "    python main.py --full                 # Run complete pipeline\n",
    "    python main.py --load-predict         # Load and predict\n",
    "\"\"\"\n",
    "\n",
    "import argparse\n",
    "import sys\n",
    "from model_pipeline import *\n",
    "\n",
    "def prepare_step():\n",
    "    \"\"\"Execute data preparation step.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 1: DATA PREPARATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        df, feature_cols = prepare_data(\n",
    "            CONFIG['DATASET_PATH'],\n",
    "            CONFIG['TARGET_COLUMN'],\n",
    "            CONFIG['CATEGORICAL_COLS']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\n‚úÖ Data preparation completed!\")\n",
    "        print(f\"   Dataset shape: {df.shape}\")\n",
    "        print(f\"   Features: {len(feature_cols)}\")\n",
    "        print(f\"   Missing values: {df.isnull().sum().sum()}\")\n",
    "        \n",
    "        return df, feature_cols\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during data preparation: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def train_step(df, feature_cols, tune=False):\n",
    "    \"\"\"Execute model training step.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 2: MODEL TRAINING\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Split data\n",
    "        X_train, X_test, y_train, y_test = split_data(\n",
    "            df, feature_cols, CONFIG['TARGET_COLUMN']\n",
    "        )\n",
    "        \n",
    "        print(f\"\\nData split:\")\n",
    "        print(f\"   Train set: {X_train.shape}\")\n",
    "        print(f\"   Test set: {X_test.shape}\")\n",
    "        \n",
    "        # Get numeric and categorical columns\n",
    "        numeric_cols, categorical_cols = get_numeric_categorical_cols(\n",
    "            df, CONFIG['CATEGORICAL_COLS']\n",
    "        )\n",
    "        \n",
    "        # Create preprocessor\n",
    "        preprocessor = create_preprocessor(numeric_cols, categorical_cols)\n",
    "        \n",
    "        # Train or tune model\n",
    "        if tune:\n",
    "            print(f\"\\nüîç Tuning model (this may take a moment)...\")\n",
    "            model = tune_model(X_train, y_train, preprocessor)\n",
    "            print(f\"‚úÖ Model tuning completed!\")\n",
    "        else:\n",
    "            print(f\"\\nüöÄ Training model...\")\n",
    "            model = train_model(X_train, y_train, preprocessor, n_neighbors=5)\n",
    "            print(f\"‚úÖ Model training completed!\")\n",
    "        \n",
    "        return model, X_train, X_test, y_train, y_test, preprocessor\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during model training: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def evaluate_step(model, X_test, y_test):\n",
    "    \"\"\"Execute model evaluation step.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 3: MODEL EVALUATION\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        metrics = evaluate_model(model, X_test, y_test)\n",
    "        \n",
    "        print(f\"\\nüìä Model Performance Metrics:\")\n",
    "        print_metrics(metrics, \"KNN Model\")\n",
    "        \n",
    "        return metrics\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during evaluation: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def save_step(model, preprocessor):\n",
    "    \"\"\"Execute model and preprocessor saving step.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 4: SAVING MODEL\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        save_model(model, CONFIG['MODEL_SAVE_PATH'])\n",
    "        save_preprocessor(preprocessor, CONFIG['PREPROCESSOR_SAVE_PATH'])\n",
    "        \n",
    "        print(f\"\\n‚úÖ Model saved successfully!\")\n",
    "        print(f\"   Model path: {CONFIG['MODEL_SAVE_PATH']}\")\n",
    "        print(f\"   Preprocessor path: {CONFIG['PREPROCESSOR_SAVE_PATH']}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during saving: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def load_predict_step():\n",
    "    \"\"\"Load model and make predictions.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"STEP 5: LOAD MODEL & PREDICT\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    try:\n",
    "        # Load model and preprocessor\n",
    "        model = load_model(CONFIG['MODEL_SAVE_PATH'])\n",
    "        preprocessor = load_preprocessor(CONFIG['PREPROCESSOR_SAVE_PATH'])\n",
    "        \n",
    "        print(f\"\\n‚úÖ Model loaded successfully!\")\n",
    "        print(f\"   Model: {CONFIG['MODEL_SAVE_PATH']}\")\n",
    "        print(f\"   Preprocessor: {CONFIG['PREPROCESSOR_SAVE_PATH']}\")\n",
    "        \n",
    "        # Prepare test data\n",
    "        df, feature_cols = prepare_data(\n",
    "            CONFIG['DATASET_PATH'],\n",
    "            CONFIG['TARGET_COLUMN'],\n",
    "            CONFIG['CATEGORICAL_COLS']\n",
    "        )\n",
    "        \n",
    "        X_train, X_test, y_train, y_test = split_data(\n",
    "            df, feature_cols, CONFIG['TARGET_COLUMN']\n",
    "        )\n",
    "        \n",
    "        # Make predictions\n",
    "        y_pred = model.predict(X_test)\n",
    "        \n",
    "        # Calculate metrics\n",
    "        metrics = evaluate_model(model, X_test, y_test)\n",
    "        print_metrics(metrics, \"Loaded KNN Model\")\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Error during load/predict: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "def full_pipeline_step(tune=False):\n",
    "    \"\"\"Execute complete pipeline.\"\"\"\n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"COMPLETE ML PIPELINE\")\n",
    "    print(\"=\"*70)\n",
    "    \n",
    "    # Step 1: Prepare\n",
    "    df, feature_cols = prepare_step()\n",
    "    \n",
    "    # Step 2: Train\n",
    "    model, X_train, X_test, y_train, y_test, preprocessor = train_step(df, feature_cols, tune=tune)\n",
    "    \n",
    "    # Step 3: Evaluate\n",
    "    metrics = evaluate_step(model, X_test, y_test)\n",
    "    \n",
    "    # Step 4: Save\n",
    "    save_step(model, preprocessor)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*70)\n",
    "    print(\"‚úÖ PIPELINE COMPLETED SUCCESSFULLY\")\n",
    "    print(\"=\"*70 + \"\\n\")\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main CLI entry point with argument parsing.\"\"\"\n",
    "    \n",
    "    parser = argparse.ArgumentParser(\n",
    "        description='ML Pipeline: Data Preparation, Training, Evaluation, Saving',\n",
    "        formatter_class=argparse.RawDescriptionHelpFormatter,\n",
    "        epilog=\"\"\"\n",
    "EXAMPLES:\n",
    "  python main.py --prepare              Run data preparation only\n",
    "  python main.py --train                Run training only\n",
    "  python main.py --evaluate             Run evaluation only\n",
    "  python main.py --save                 Save trained model\n",
    "  python main.py --full                 Run complete pipeline\n",
    "  python main.py --full --tune          Run pipeline with hyperparameter tuning\n",
    "  python main.py --load-predict         Load model and make predictions\n",
    "  \n",
    "PIPELINE WORKFLOW:\n",
    "  1. --prepare   : Load and preprocess data\n",
    "  2. --train     : Train KNN model\n",
    "  3. --evaluate  : Evaluate model performance\n",
    "  4. --save      : Save model and preprocessor\n",
    "  5. --full      : Execute all steps (1-4)\n",
    "        \"\"\"\n",
    "    )\n",
    "    \n",
    "    # Create mutually exclusive group for main operations\n",
    "    operation = parser.add_mutually_exclusive_group(required=True)\n",
    "    \n",
    "    operation.add_argument(\n",
    "        '--prepare',\n",
    "        action='store_true',\n",
    "        help='Execute data preparation step only'\n",
    "    )\n",
    "    \n",
    "    operation.add_argument(\n",
    "        '--train',\n",
    "        action='store_true',\n",
    "        help='Execute model training step only'\n",
    "    )\n",
    "    \n",
    "    operation.add_argument(\n",
    "        '--evaluate',\n",
    "        action='store_true',\n",
    "        help='Execute model evaluation step only'\n",
    "    )\n",
    "    \n",
    "    operation.add_argument(\n",
    "        '--save',\n",
    "        action='store_true',\n",
    "        help='Execute model saving step'\n",
    "    )\n",
    "    \n",
    "    operation.add_argument(\n",
    "        '--full',\n",
    "        action='store_true',\n",
    "        help='Execute complete pipeline (prepare ‚Üí train ‚Üí evaluate ‚Üí save)'\n",
    "    )\n",
    "    \n",
    "    operation.add_argument(\n",
    "        '--load-predict',\n",
    "        action='store_true',\n",
    "        help='Load saved model and make predictions'\n",
    "    )\n",
    "    \n",
    "    # Optional arguments\n",
    "    parser.add_argument(\n",
    "        '--tune',\n",
    "        action='store_true',\n",
    "        help='Use hyperparameter tuning during training (slower but better)'\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--dataset',\n",
    "        type=str,\n",
    "        default=CONFIG['DATASET_PATH'],\n",
    "        help=f\"Path to dataset (default: {CONFIG['DATASET_PATH']})\"\n",
    "    )\n",
    "    \n",
    "    parser.add_argument(\n",
    "        '--model-path',\n",
    "        type=str,\n",
    "        default=CONFIG['MODEL_SAVE_PATH'],\n",
    "        help=f\"Path to save/load model (default: {CONFIG['MODEL_SAVE_PATH']})\"\n",
    "    )\n",
    "    \n",
    "    # Parse arguments\n",
    "    args = parser.parse_args()\n",
    "    \n",
    "    # Update config if custom paths provided\n",
    "    if args.dataset:\n",
    "        CONFIG['DATASET_PATH'] = args.dataset\n",
    "    if args.model_path:\n",
    "        CONFIG['MODEL_SAVE_PATH'] = args.model_path\n",
    "    \n",
    "    # Execute based on arguments\n",
    "    try:\n",
    "        if args.prepare:\n",
    "            df, feature_cols = prepare_step()\n",
    "            print(\"\\nüíæ To train model, run: python main.py --train\")\n",
    "        \n",
    "        elif args.train:\n",
    "            print(\"\\n‚ö†Ô∏è  Running training requires prepared data.\")\n",
    "            print(\"   Run 'python main.py --full' for complete pipeline\")\n",
    "            print(\"   Or run 'python main.py --prepare' first\")\n",
    "            df, feature_cols = prepare_step()\n",
    "            model, X_train, X_test, y_train, y_test, preprocessor = train_step(\n",
    "                df, feature_cols, tune=args.tune\n",
    "            )\n",
    "            print(\"\\nüíæ To evaluate, run: python main.py --evaluate\")\n",
    "        \n",
    "        elif args.evaluate:\n",
    "            print(\"\\n‚ö†Ô∏è  Running evaluation requires trained model.\")\n",
    "            print(\"   Run 'python main.py --full' for complete pipeline\")\n",
    "            print(\"   Or run 'python main.py --train' first\")\n",
    "            df, feature_cols = prepare_step()\n",
    "            model, X_train, X_test, y_train, y_test, preprocessor = train_step(\n",
    "                df, feature_cols, tune=args.tune\n",
    "            )\n",
    "            metrics = evaluate_step(model, X_test, y_test)\n",
    "            print(\"\\nüíæ To save model, run: python main.py --save\")\n",
    "        \n",
    "        elif args.save:\n",
    "            print(\"\\n‚ö†Ô∏è  Running save requires trained model.\")\n",
    "            print(\"   Run 'python main.py --full' for complete pipeline\")\n",
    "            print(\"   Or run 'python main.py --train' first\")\n",
    "            df, feature_cols = prepare_step()\n",
    "            model, X_train, X_test, y_train, y_test, preprocessor = train_step(\n",
    "                df, feature_cols, tune=args.tune\n",
    "            )\n",
    "            save_step(model, preprocessor)\n",
    "        \n",
    "        elif args.full:\n",
    "            full_pipeline_step(tune=args.tune)\n",
    "        \n",
    "        elif args.load_predict:\n",
    "            load_predict_step()\n",
    "    \n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\n\\n‚ö†Ô∏è  Pipeline interrupted by user\")\n",
    "        sys.exit(0)\n",
    "    except Exception as e:\n",
    "        print(f\"\\n‚ùå Pipeline failed: {str(e)}\")\n",
    "        sys.exit(1)\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d525505",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
