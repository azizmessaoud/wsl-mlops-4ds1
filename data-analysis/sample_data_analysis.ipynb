{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Analysis Workflow Example\n",
    "\n",
    "This notebook demonstrates a typical data analysis workflow using Python and common data science libraries.\n",
    "\n",
    "## Workflow Steps:\n",
    "1. Import libraries\n",
    "2. Load and explore data\n",
    "3. Data cleaning and preprocessing\n",
    "4. Exploratory Data Analysis (EDA)\n",
    "5. Statistical analysis\n",
    "6. Visualization\n",
    "7. Conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data manipulation\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine Learning\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('seaborn-v0_8-darkgrid')\n",
    "sns.set_palette('husl')\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load and Explore Data\n",
    "\n",
    "For this example, we'll create a synthetic dataset to demonstrate the workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Create synthetic data\n",
    "n_samples = 1000\n",
    "\n",
    "# Generate features\n",
    "age = np.random.randint(18, 70, n_samples)\n",
    "experience = np.random.randint(0, 40, n_samples)\n",
    "education_level = np.random.choice(['High School', 'Bachelor', 'Master', 'PhD'], n_samples)\n",
    "\n",
    "# Generate target variable (salary) with some correlation to features\n",
    "base_salary = 30000\n",
    "salary = (base_salary + \n",
    "          age * 500 + \n",
    "          experience * 1200 + \n",
    "          np.random.normal(0, 5000, n_samples))\n",
    "\n",
    "# Create DataFrame\n",
    "df = pd.DataFrame({\n",
    "    'age': age,\n",
    "    'experience': experience,\n",
    "    'education': education_level,\n",
    "    'salary': salary\n",
    "})\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "df.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display basic information about the dataset\n",
    "print(\"\\nDataset Info:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display statistical summary\n",
    "print(\"\\nStatistical Summary:\")\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Data Cleaning and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "print(\"Missing values per column:\")\n",
    "print(df.isnull().sum())\n",
    "\n",
    "# Check for duplicates\n",
    "print(f\"\\nNumber of duplicate rows: {df.duplicated().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode categorical variables\n",
    "education_mapping = {\n",
    "    'High School': 1,\n",
    "    'Bachelor': 2,\n",
    "    'Master': 3,\n",
    "    'PhD': 4\n",
    "}\n",
    "\n",
    "df['education_encoded'] = df['education'].map(education_mapping)\n",
    "\n",
    "print(\"Education encoding:\")\n",
    "print(df[['education', 'education_encoded']].drop_duplicates().sort_values('education_encoded'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of education levels\n",
    "print(\"Education distribution:\")\n",
    "print(df['education'].value_counts())\n",
    "\n",
    "# Correlation analysis\n",
    "print(\"\\nCorrelation with salary:\")\n",
    "numeric_cols = ['age', 'experience', 'education_encoded', 'salary']\n",
    "print(df[numeric_cols].corr()['salary'].sort_values(ascending=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Data Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a figure with multiple subplots\n",
    "fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "# 1. Salary distribution\n",
    "axes[0, 0].hist(df['salary'], bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0, 0].set_xlabel('Salary')\n",
    "axes[0, 0].set_ylabel('Frequency')\n",
    "axes[0, 0].set_title('Salary Distribution')\n",
    "axes[0, 0].axvline(df['salary'].mean(), color='red', linestyle='--', label=f'Mean: ${df[\"salary\"].mean():,.0f}')\n",
    "axes[0, 0].legend()\n",
    "\n",
    "# 2. Salary vs Experience\n",
    "axes[0, 1].scatter(df['experience'], df['salary'], alpha=0.5)\n",
    "axes[0, 1].set_xlabel('Years of Experience')\n",
    "axes[0, 1].set_ylabel('Salary')\n",
    "axes[0, 1].set_title('Salary vs Experience')\n",
    "\n",
    "# 3. Salary vs Age\n",
    "axes[1, 0].scatter(df['age'], df['salary'], alpha=0.5, color='green')\n",
    "axes[1, 0].set_xlabel('Age')\n",
    "axes[1, 0].set_ylabel('Salary')\n",
    "axes[1, 0].set_title('Salary vs Age')\n",
    "\n",
    "# 4. Salary by Education Level\n",
    "df.boxplot(column='salary', by='education', ax=axes[1, 1])\n",
    "axes[1, 1].set_xlabel('Education Level')\n",
    "axes[1, 1].set_ylabel('Salary')\n",
    "axes[1, 1].set_title('Salary Distribution by Education Level')\n",
    "plt.suptitle('')  # Remove default title\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "correlation_matrix = df[numeric_cols].corr()\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', center=0, \n",
    "            square=True, linewidths=1, cbar_kws={\"shrink\": 0.8})\n",
    "plt.title('Correlation Heatmap')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pairplot for quick visual analysis\n",
    "sns.pairplot(df[numeric_cols], diag_kind='kde', corner=True)\n",
    "plt.suptitle('Pairplot of Numeric Features', y=1.02)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Statistical Analysis and Simple Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare data for modeling\n",
    "X = df[['age', 'experience', 'education_encoded']]\n",
    "y = df['salary']\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "print(f\"Training set size: {X_train.shape[0]}\")\n",
    "print(f\"Testing set size: {X_test.shape[0]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train a simple linear regression model\n",
    "model = LinearRegression()\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Make predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluate the model\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse = np.sqrt(mse)\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(\"Model Performance:\")\n",
    "print(f\"Root Mean Squared Error: ${rmse:,.2f}\")\n",
    "print(f\"R² Score: {r2:.4f}\")\n",
    "\n",
    "# Display feature coefficients\n",
    "print(\"\\nFeature Coefficients:\")\n",
    "for feature, coef in zip(X.columns, model.coef_):\n",
    "    print(f\"{feature}: ${coef:,.2f}\")\n",
    "print(f\"Intercept: ${model.intercept_:,.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize predictions vs actual values\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "plt.xlabel('Actual Salary')\n",
    "plt.ylabel('Predicted Salary')\n",
    "plt.title('Actual vs Predicted Salary')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual plot\n",
    "residuals = y_test - y_pred\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(y_pred, residuals, alpha=0.5)\n",
    "plt.axhline(y=0, color='r', linestyle='--')\n",
    "plt.xlabel('Predicted Salary')\n",
    "plt.ylabel('Residuals')\n",
    "plt.title('Residual Plot')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Conclusions\n",
    "\n",
    "This notebook demonstrated a complete data analysis workflow:\n",
    "\n",
    "### Key Findings:\n",
    "- Experience shows a strong positive correlation with salary\n",
    "- Age also correlates positively with salary\n",
    "- Education level has an impact on salary ranges\n",
    "\n",
    "### Workflow Summary:\n",
    "1. **Data Loading**: Created a synthetic dataset for demonstration\n",
    "2. **Data Exploration**: Examined data structure, types, and basic statistics\n",
    "3. **Data Cleaning**: Checked for missing values and duplicates\n",
    "4. **Feature Engineering**: Encoded categorical variables\n",
    "5. **Visualization**: Created multiple plots to understand relationships\n",
    "6. **Modeling**: Built a simple linear regression model\n",
    "7. **Evaluation**: Assessed model performance using RMSE and R² metrics\n",
    "\n",
    "### Next Steps:\n",
    "- Try more advanced models (Random Forest, Gradient Boosting)\n",
    "- Feature selection and engineering\n",
    "- Cross-validation for better model evaluation\n",
    "- Hyperparameter tuning\n",
    "- Deploy the model for predictions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
